\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\BKM@entry[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{WileyNJD-AMA}
\BKM@entry{id=1,open,dest={446F632D5374617274},srcline={77}}{5768656E20746F20496D707574653F20496D7075746174696F6E206265666F726520616E6420647572696E672063726F73732D76616C69646174696F6E}
\BKM@entry{id=2,open,dest={446F632D5374617274},srcline={77}}{4162737472616374}
\BKM@entry{id=3,open,dest={73656374696F6E2E31},srcline={79}}{496E74726F64756374696F6E}
\citation{kuhn2013applied}
\citation{arlot2010survey}
\@writefile{toc}{\contentsline {chapter}{When to Impute? Imputation before and during cross-validation}{1}{Doc-Start}\protected@file@percent }
\Newlabel{a}{1}
\Newlabel{b}{2}
\Newlabel{c}{3}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{mlr3}
\citation{hastie2009elements}
\citation{stekhoven2011missforest}
\BKM@entry{id=4,open,dest={73656374696F6E2E32},srcline={172}}{4D697373696E672064617461}
\citation{rubin1976inference}
\citation{twala2008good,twala2009empirical,tang2017random}
\citation{van2018flexible}
\@writefile{toc}{\contentsline {section}{\numberline {2}Missing data}{3}{section.2}\protected@file@percent }
\newlabel{sec:missing_data}{{2}{3}{Missing data}{section.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Missing data mechanisms}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Missing data strategies for statistical inference}{3}{section.2}\protected@file@percent }
\citation{kuhn2019feature}
\citation{jerez2010missing}
\BKM@entry{id=5,open,dest={73656374696F6E2E33},srcline={237}}{4F72646572206F66204F7065726174696F6E73}
\citation{breiman}
\citation{hastie2009elements}
\citation{neunhoeffer2019cross}
\@writefile{toc}{\contentsline {paragraph}{Missing data strategies for statistical prediction}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Order of Operations}{4}{section.3}\protected@file@percent }
\newlabel{sec:oop}{{3}{4}{Order of Operations}{section.3}{}}
\BKM@entry{id=6,open,dest={73756273656374696F6E2E332E31},srcline={299}}{54657374696E672064617461}
\citation{softImpute}
\BKM@entry{id=7,open,dest={73656374696F6E2E34},srcline={322}}{53696D756C61746564206578706572696D656E7473}
\citation{morris2019using}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Testing data}{5}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:testing_data}{{3.1}{5}{Testing data}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulated experiments}{5}{section.4}\protected@file@percent }
\newlabel{sec:sim}{{4}{5}{Simulated experiments}{section.4}{}}
\BKM@entry{id=8,open,dest={73756273656374696F6E2E342E31},srcline={341}}{446174612D67656E65726174696E67206D656368616E69736D73}
\citation{mice}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data-generating mechanisms}{6}{subsection.4.1}\protected@file@percent }
\newlabel{subsec:data_gen}{{4.1}{6}{Data-generating mechanisms}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Data generation scenarios}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Amputing data}{6}{subsection.4.1}\protected@file@percent }
\citation{tibshirani1996regression}
\citation{gower1971general}
\citation{glmnet}
\BKM@entry{id=9,open,dest={73756273656374696F6E2E342E32},srcline={445}}{526573756C7473}
\@writefile{toc}{\contentsline {paragraph}{Modeling procedure}{7}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Analysis plan}{7}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results}{7}{subsection.4.2}\protected@file@percent }
\newlabel{subsec:sim_results}{{4.2}{7}{Results}{subsection.4.2}{}}
\BKM@entry{id=10,open,dest={73656374696F6E2E35},srcline={524}}{5265616C2064617461206578706572696D656E7473}
\citation{de2011ames}
\citation{AmesHousing}
\@writefile{toc}{\contentsline {paragraph}{Bias, variance, and RMSE}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Downstream model performance}{8}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Real data experiments}{8}{section.5}\protected@file@percent }
\newlabel{sec:app}{{5}{8}{Real data experiments}{section.5}{}}
\citation{breiman2001random}
\BKM@entry{id=11,open,dest={73756273656374696F6E2E352E31},srcline={574}}{526573756C7473}
\@writefile{toc}{\contentsline {paragraph}{Ames, Iowa housing data}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Analysis plan}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Amputing data}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Results}{9}{subsection.5.1}\protected@file@percent }
\BKM@entry{id=12,open,dest={73656374696F6E2E36},srcline={625}}{44697363757373696F6E20616E64207265636F6D6D656E646174696F6E73}
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{10}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion and recommendations}{10}{section.6}\protected@file@percent }
\newlabel{sec:discuss}{{6}{10}{Discussion and recommendations}{section.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces True external $R^2$ mean (standard deviation) values for the modeling technique that is internally assessed using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{12}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:ext_rsq}{{1}{12}{True external $R^2$ mean (standard deviation) values for the modeling technique that is internally assessed using $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Mean (standard deviation) absolute differences in estimates of external $R^2$ between $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{12}{table.caption.2}\protected@file@percent }
\newlabel{tab:cv_diffs}{{2}{12}{Mean (standard deviation) absolute differences in estimates of external $R^2$ between $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Bias of external $R^2$ estimates using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{13}{table.caption.3}\protected@file@percent }
\newlabel{tab:bias}{{3}{13}{Bias of external $R^2$ estimates using $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Standard deviation of external $R^2$ estimates using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{14}{table.caption.4}\protected@file@percent }
\newlabel{tab:variance}{{4}{14}{Standard deviation of external $R^2$ estimates using $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Root-mean-squared error of external $R^2$ estimates using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{15}{table.caption.5}\protected@file@percent }
\newlabel{tab:rmse}{{5}{15}{Root-mean-squared error of external $R^2$ estimates using $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Mean external $R^2$ when $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ and $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$ were applied to tune the number of neighbors used for imputation. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref  {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }}{16}{table.caption.6}\protected@file@percent }
\newlabel{tab:tune}{{6}{16}{Mean external $R^2$ when $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space and $\texttt {I}\!\!\rightarrow \!\texttt {CV}$\space were applied to tune the number of neighbors used for imputation. Descriptions of scenarios 1, 2, and 3 are provided in Section \ref {subsec:data_gen}. All table values are scaled by 100 for convenience\relax }{table.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A workflow to develop and validate a pipeline modeling algorithm. Pipeline parameter values may be set apriori or determined empirically using cross validation. Once parameter values are fixed, a final model is developed by training the modeling pipeline using the training data. The final model is externally validated by assessing the accuracy of its predictions in the testing data.\relax }}{17}{figure.caption.7}\protected@file@percent }
\newlabel{fig:workflow_ml}{{1}{17}{A workflow to develop and validate a pipeline modeling algorithm. Pipeline parameter values may be set apriori or determined empirically using cross validation. Once parameter values are fixed, a final model is developed by training the modeling pipeline using the training data. The final model is externally validated by assessing the accuracy of its predictions in the testing data.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Workflows for cross validation (CV) incorporating imputation of missing values. The difference in the workflows is where imputation is performed. The standard workflow, $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$, imputes missing values during each replicate of CV. The experimental workflow, $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$, imputes missing values prior to CV. Critically, $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$ means imputation happens once, whereas in $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ the imputation procedure occurs for each fold, adding computational time.\relax }}{18}{figure.caption.8}\protected@file@percent }
\newlabel{fig:workflow_cv_bothways}{{2}{18}{Workflows for cross validation (CV) incorporating imputation of missing values. The difference in the workflows is where imputation is performed. The standard workflow, $\texttt {CV}\!\circlearrowright \!\texttt {I}$, imputes missing values during each replicate of CV. The experimental workflow, $\texttt {I}\!\!\rightarrow \!\texttt {CV}$, imputes missing values prior to CV. Critically, $\texttt {I}\!\!\rightarrow \!\texttt {CV}$\space means imputation happens once, whereas in $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space the imputation procedure occurs for each fold, adding computational time.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces External generalization error and internal estimates of generalization error using $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$ and $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$. The $R^2$ values are plotted as a function of the number of nearest neighbors used to impute missing data, and the panel rows show results with 100, 500, 1000, and 5000 observations in the training data. The scenarios are described in Section \ref  {subsec:data_gen}. The peaks of all three curves consistently appear to be at the same number of neighbors. While $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$ error estimates have a slight positive bias, as noted in section \ref  {subsec:sim_results}, they also have less variability than error estimates using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$.\relax }}{19}{figure.caption.9}\protected@file@percent }
\newlabel{fig:sim_r2}{{3}{19}{External generalization error and internal estimates of generalization error using $\texttt {I}\!\!\rightarrow \!\texttt {CV}$\space and $\texttt {CV}\!\circlearrowright \!\texttt {I}$. The $R^2$ values are plotted as a function of the number of nearest neighbors used to impute missing data, and the panel rows show results with 100, 500, 1000, and 5000 observations in the training data. The scenarios are described in Section \ref {subsec:data_gen}. The peaks of all three curves consistently appear to be at the same number of neighbors. While $\texttt {I}\!\!\rightarrow \!\texttt {CV}$\space error estimates have a slight positive bias, as noted in section \ref {subsec:sim_results}, they also have less variability than error estimates using $\texttt {CV}\!\circlearrowright \!\texttt {I}$.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces External generalization error (y-axis) and time required to impute missing values (x-axis) for the Ames housing data. $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$ and $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ were applied, separately, to select $k$, the number of nearest neighbors used to impute missing values, prior to fitting and externally validating a prediction model. While the median generalization error is practically equivalent regardless of which CV method was used, the time required for imputation is approximately 10 (\textit  {i.e., }the number of folds in CV) times higher using $\texttt  {CV}\tmspace  -\thinmuskip {.1667em}\circlearrowright \tmspace  -\thinmuskip {.1667em}\texttt  {I}$ versus $\texttt  {I}\tmspace  -\thinmuskip {.1667em}\tmspace  -\thinmuskip {.1667em}\rightarrow \tmspace  -\thinmuskip {.1667em}\texttt  {CV}$.\relax }}{20}{figure.caption.10}\protected@file@percent }
\newlabel{fig:ames_cmp_time}{{4}{20}{External generalization error (y-axis) and time required to impute missing values (x-axis) for the Ames housing data. $\texttt {I}\!\!\rightarrow \!\texttt {CV}$\space and $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space were applied, separately, to select $k$, the number of nearest neighbors used to impute missing values, prior to fitting and externally validating a prediction model. While the median generalization error is practically equivalent regardless of which CV method was used, the time required for imputation is approximately 10 (\textit {i.e., }the number of folds in CV) times higher using $\texttt {CV}\!\circlearrowright \!\texttt {I}$\space versus $\texttt {I}\!\!\rightarrow \!\texttt {CV}$.\relax }{figure.caption.10}{}}
\bibdata{bibfile.bib}
\BKM@entry{id=13,open,dest={6669677572652E63617074696F6E2E3130},srcline={1}}{5265666572656E636573}
\bibcite{kuhn2013applied}{{1}{}{{}}{{}}}
\bibcite{arlot2010survey}{{2}{}{{}}{{}}}
\bibcite{mlr3}{{3}{}{{}}{{}}}
\bibcite{hastie2009elements}{{4}{}{{}}{{}}}
\bibcite{stekhoven2011missforest}{{5}{}{{}}{{}}}
\bibcite{rubin1976inference}{{6}{}{{}}{{}}}
\bibcite{twala2008good}{{7}{}{{}}{{}}}
\bibcite{twala2009empirical}{{8}{}{{}}{{}}}
\bibcite{tang2017random}{{9}{}{{}}{{}}}
\bibcite{van2018flexible}{{10}{}{{}}{{}}}
\bibcite{kuhn2019feature}{{11}{}{{}}{{}}}
\bibcite{jerez2010missing}{{12}{}{{}}{{}}}
\bibcite{breiman}{{13}{}{{}}{{}}}
\bibcite{neunhoeffer2019cross}{{14}{}{{}}{{}}}
\bibcite{softImpute}{{15}{}{{}}{{}}}
\bibcite{morris2019using}{{16}{}{{}}{{}}}
\bibcite{mice}{{17}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{References\begingroup \let \let \let \let \@unexpandable@protect \xdef {\MakeUppercase  {References}}{\MakeUppercase  {References}}{{\MakeUppercase  {References}}{\MakeUppercase  {References}}}\@temptokena {{\MakeUppercase  {References}}{\MakeUppercase  {References}}}\mark {\thm@preskip 6.0pt\thm@postskip 6.0pt\relax \thm@headfont {\bfseries  }\thm@headpunct {.}}\endgroup }{21}{figure.caption.10}\protected@file@percent }
\bibcite{tibshirani1996regression}{{18}{}{{}}{{}}}
\bibcite{gower1971general}{{19}{}{{}}{{}}}
\bibcite{glmnet}{{20}{}{{}}{{}}}
\bibcite{de2011ames}{{21}{}{{}}{{}}}
\bibcite{AmesHousing}{{22}{}{{}}{{}}}
\bibcite{breiman2001random}{{23}{}{{}}{{}}}
\FirstPg{0}\LastPg{21}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
